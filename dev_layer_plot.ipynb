{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import geopandas as gpd\n",
    "import plotly.io as pio\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from cmcrameri import cm\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from pandas import concat, DataFrame, read_csv\n",
    "from numpy import arange, array, linspace\n",
    "from IPython.display import HTML\n",
    "\n",
    "import functions as ft\n",
    "\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb69b5fb",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "ToDo\n",
    "- describe workflow\n",
    "- 0 replace by average of the surrounding; start from bottom to top indicate estimate as True (additional parameter) - to be saved\n",
    "- map-batchID vs geo coordinates as JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb6a9c",
   "metadata": {},
   "source": [
    "# User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0362c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_address = \"Depot Boijmans Van Beuningen\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03126585",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://service.pdok.nl/cbs/gebiedsindelingen/2025/wfs/v1_0?request=GetFeature&service=WFS&version=2.0.0&typeName=gemeente_gegeneraliseerd&outputFormat=json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_openstreetmap = \"https://nominatim.openstreetmap.org/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_geotop = 'input/GeoTOP_v01r6s1_csv_bestanden/'\n",
    "dir_export = 'output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b48ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# projections for different coordinate systems\n",
    "projection_rd_amersfoort = 'epsg:28992'\n",
    "projection_geocoordinates = 'epsg:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_lithoclasses = dict({\n",
    "    0: 'NaN', 1: 'veen', 2: 'klei', 3: 'kleiig_zand', \n",
    "    4: 'vervallen', 5: 'zand_fijn', 6: 'zand_matig_grof',\n",
    "    7: 'zand_grof', 8: 'grind', 9: 'schelpen'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "material_color_mapping = dict({\n",
    "    'NaN': '#ffffff',\n",
    "    'veen': '#64564c',\n",
    "    'klei':'#b2a38d', \n",
    "    'kleiig_zand':'#8a8783', \n",
    "    'vervallen':'#ee82ee', \n",
    "    'zand_fijn':'#000000', \n",
    "    'zand_matig_grof': '#c5c5c5',  \n",
    "    'zand_grof': '#616160',\n",
    "    'grind': '#ffff82',\n",
    "    'schelpen': '#eb611e' \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_color = '#333333'\n",
    "fontsize = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Get coordinates from User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not user_input_address:\n",
    "    latitude, longitude = 51.9139529, 4.4711320\n",
    "    print(f\"No user input defined; fall back to default: {latitude}, {longitude} (lat, lon)\")\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        geo = requests.get(\n",
    "            url_openstreetmap, \n",
    "            headers={\"User-Agent\": \"CaraLogic (contact: silvia@caralogic.com)\"}, \n",
    "            params={\"q\": user_input_address, \"format\": \"json\", \"limit\": 1}\n",
    "            )\n",
    "\n",
    "        geo.raise_for_status()\n",
    "        if len(geo.json()) == 0:\n",
    "            print(f\"no data found for {user_input_address}\")\n",
    "            latitude, longitude = None, None\n",
    "        else:  \n",
    "            location = geo.json()[0]\n",
    "            latitude, longitude = float(location['lat']), float(location['lon']) \n",
    "    except:\n",
    "        latitude, longitude = 51.9139529, 4.4711320\n",
    "\n",
    "    print(f\"Coordinates found for {user_input_address}: {latitude}, {longitude} (lat, lon)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Get and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Get GeoTop Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_files = sorted([file for file in glob(dir_geotop + '*.csv')])\n",
    "ls_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b0cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_data = [read_csv(file, index_col=[0,1,2], engine=\"pyarrow\") for file in ls_files]\n",
    "\n",
    "data = concat(ls_data).sort_index()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9542e921",
   "metadata": {},
   "source": [
    "## Focus on City of Rotterdam\n",
    "\n",
    "#### Get Rotterdam City Boundary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities = gpd.read_file(url)\n",
    "municipalities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotterdam = municipalities[municipalities[\"statnaam\"] == \"Rotterdam\"]\n",
    "\n",
    "rotterdam_rd = rotterdam.to_crs(epsg=projection_rd_amersfoort.split('epsg:')[1])\n",
    "rotterdam_rd_json = json.loads(rotterdam_rd.to_json())\n",
    "\n",
    "rotterdam_geo = rotterdam.to_crs(epsg=projection_geocoordinates.split('epsg:')[1])\n",
    "rotterdam_geo_json = json.loads(rotterdam_geo.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotterdam_rd_border = DataFrame(rotterdam_rd_json['features'][0]['geometry']['coordinates'][0][0], columns=['x', 'y'])\n",
    "rotterdam_rd_border"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ec856",
   "metadata": {},
   "source": [
    "#### Crop To Rotterdam City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a6be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_points = gpd.GeoDataFrame(\n",
    "    data, \n",
    "    geometry=gpd.points_from_xy(data.reset_index().x, data.reset_index().y), \n",
    "    crs=projection_rd_amersfoort\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133af0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_in_rotterdam = gdf_points[gdf_points.geometry.within(rotterdam_rd.union_all())]\n",
    "points_in_rotterdam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866271d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data points available within Rotterdam {points_in_rotterdam.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f4e32",
   "metadata": {},
   "source": [
    "## Convert RD-Coordinates to Geo-Coordinates \n",
    "\n",
    "and plot in 2D plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_in_rotterdam = ft.convert_rd_into_geocoordinates(points_in_rotterdam)\n",
    "points_in_rotterdam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pairs = points_in_rotterdam.reset_index()[['lat', 'lon']].drop_duplicates()\n",
    "\n",
    "df_unique_pairs = points_in_rotterdam.reset_index().loc[unique_pairs.index]\n",
    "df_unique_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_lat, center_lon = unique_pairs.median()\n",
    "\n",
    "fig = px.scatter_map(\n",
    "    df_unique_pairs,\n",
    "    lat=\"lat\", lon=\"lon\", center={\"lat\": center_lat, \"lon\": center_lon},\n",
    "    zoom=9, height=600, map_style=\"carto-positron\"\n",
    "    )\n",
    "\n",
    "for feature in rotterdam_geo_json[\"features\"]:\n",
    "    fig.add_trace(go.Scattermapbox(\n",
    "        lat=[\n",
    "            coord[1] for polygon in feature[\"geometry\"][\"coordinates\"] \n",
    "            for coord in (polygon[0] if feature[\"geometry\"][\"type\"] == \"MultiPolygon\" else polygon)\n",
    "            ],\n",
    "        lon=[\n",
    "            coord[0] for polygon in feature[\"geometry\"][\"coordinates\"] \n",
    "            for coord in (polygon[0] if feature[\"geometry\"][\"type\"] == \"MultiPolygon\" else polygon)\n",
    "            ],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"red\", width=3),\n",
    "        name=\"Rotterdam boundary\"\n",
    "    ))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "if save:\n",
    "    print('exporting figure rotterdam_datapoints.html... ')\n",
    "    pio.write_html(fig, \"output/rotterdam_datapoints.html\", full_html=True, include_plotlyjs='cdn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# Find Data Points in Data Set from Input\n",
    "\n",
    "### Get Box Around Address "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"finding closest point to {longitude}, {latitude}:\\n\")\n",
    "points_around_input = ft.find_closest_points_to_input(\n",
    "    data=points_in_rotterdam, latitude=latitude, longitude=longitude, delta_lat=0.002, delta_lon=0.004\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62db277",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_map(points_around_input[['lat', 'lon']].drop_duplicates(), lat='lat', lon='lon', zoom=15, height=600)\n",
    "fig.update_traces(marker=dict(size=10))\n",
    "fig.update_layout(map_style=\"carto-positron\")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scattermap(\n",
    "        lat=[latitude],\n",
    "        lon=[longitude],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=16,\n",
    "            color=\"orange\",\n",
    "            symbol=\"star\" \n",
    "        ),\n",
    "        name=\"User Input {latitude}, {longitude}\".format(latitude=latitude, longitude=longitude)\n",
    "    )\n",
    ")\n",
    "\n",
    "HTML(fig.to_html(include_plotlyjs='cdn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Get Profiles for Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4818880",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_around_input['lithoklasse_material'] = [map_lithoclasses[k] for k in points_around_input.lithoklasse]\n",
    "points_around_input['lithoklasse_color'] = [material_color_mapping[c] \n",
    "                                            for c in points_around_input['lithoklasse_material']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53fdc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles, unique_points = ft.get_unique_points(points_around_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec19e30",
   "metadata": {},
   "source": [
    "# Separate Data Exploration\n",
    "\n",
    "### Class Distribution within Rotterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a2aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_in_rotterdam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "lithoclass_overview = concat([\n",
    "    points_in_rotterdam.lithoklasse.value_counts(),\n",
    "    points_in_rotterdam.lithoklasse.value_counts(normalize=True)*100], axis=1)\n",
    "\n",
    "lithoclass_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25899a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_dist = DataFrame(\n",
    "    points_in_rotterdam\n",
    "    .groupby(level='z')['lithoklasse']\n",
    "    .value_counts(normalize=True)\n",
    "    .mul(100)\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "depth_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee6e7d",
   "metadata": {},
   "source": [
    "### Visualizing Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088e0f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = depth_dist.sort_index()\n",
    "colors = cm.vik(linspace(0, 1, len(df_plot.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a29f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 7))\n",
    "df_plot.plot.area(ax=ax, cmap=cm.vik)\n",
    "\n",
    "plt.gca().invert_xaxis() \n",
    "leg = ax.legend(\n",
    "    title=\"Lithoklasse\", loc='upper left', ncols=8,\n",
    "    edgecolor=axes_color, borderpad=.65, fontsize=fontsize*0.75\n",
    "    )\n",
    "leg.get_frame().set_linewidth(.5)\n",
    "    \n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "ax.axhline(y=ax.get_ylim()[0], color=axes_color, linewidth=1.2, zorder=10)\n",
    "ax.axvline(x=ax.get_xlim()[0], color=axes_color, linewidth=1.2, zorder=10)\n",
    "\n",
    "ax.tick_params(axis='x', colors=axes_color)\n",
    "ax.tick_params(axis='y', colors=axes_color)\n",
    "\n",
    "ax.grid(False)\n",
    "ax.set_xlabel(\"Depth $z$, m\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"Percentage, %\", fontsize=fontsize)\n",
    "ax.set_title(\"Vertical Distribution of Lithology Classes\", loc='left', fontsize=fontsize*1.25)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d8cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 6))\n",
    "for i, col in enumerate(df_plot.columns):\n",
    "    sns.kdeplot(y=df_plot.index, weights=df_plot[col], bw_adjust=.2, lw=1.5, label=col, ax=ax, color=colors[i])\n",
    "\n",
    "leg = ax.legend(\n",
    "    title=\"Lithoklasse\", loc=0, ncols=8,\n",
    "    edgecolor=axes_color, borderpad=.65, fontsize=fontsize*0.75\n",
    "    )\n",
    "leg.get_frame().set_linewidth(.5)\n",
    "    \n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "ax.axhline(y=ax.get_ylim()[0], color=axes_color, linewidth=1.2, zorder=10)\n",
    "ax.axvline(x=ax.get_xlim()[0], color=axes_color, linewidth=1.2, zorder=10)\n",
    "\n",
    "ax.tick_params(axis='x', colors=axes_color)\n",
    "ax.tick_params(axis='y', colors=axes_color)\n",
    "\n",
    "ax.grid(False)\n",
    "ax.set_ylabel(\"Depth $z$, m\", fontsize=fontsize)\n",
    "ax.set_xlabel(\"Percentage, %\", fontsize=fontsize)\n",
    "ax.set_title(\"Distribution of Lithology Classes\", loc='left', fontsize=fontsize*1.25)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(df_plot, cmap=cm.batlowW_r, cbar=True, cbar_kws={'label': 'Percentage, %'}, ax=ax)\n",
    "\n",
    "plt.gca().invert_yaxis() \n",
    "plt.xticks(ticks=arange(len(df_plot.columns)), labels=df_plot.columns)\n",
    "\n",
    "plt.xlabel(\"Lithoklasse\")\n",
    "plt.ylabel(\"Depth $z$, m\")\n",
    "plt.title(\"Lithology Distribution per Depth\", loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118480a6",
   "metadata": {},
   "source": [
    "# Data Vis 3D Projection\n",
    "\n",
    "## Original Voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ft.plot_voxel(\n",
    "    unique_points, elev=30, azim=45, \n",
    "    layer_label='layers',  dx=0.002, dy=0.002, \n",
    "    save_name='output/smoothed_dataset',\n",
    "    save=False, display_plot=True, figsize=(18,6)\n",
    "    )\n",
    "\n",
    "if save:\n",
    "    print('exporting original voxel...')\n",
    "    fig.savefig(f\"output/original_voxel_around_{longitude}-{latitude}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5eaecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_original_figs = dict()\n",
    "for azim in linspace(0, 360, 12):\n",
    "    dic_original_figs[azim] = ft.plot_voxel(\n",
    "        unique_points, elev=30, azim=azim,\n",
    "        save_name='output/original_dataset', \n",
    "        layer_label='layers',  dx=0.002, dy=0.002, \n",
    "        save=True, display_plot=False, figsize=(18,6)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8649f481",
   "metadata": {},
   "source": [
    "## Smoothing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3501543",
   "metadata": {},
   "source": [
    "### Gaussian Smoothing\n",
    "also called moving average along the depth axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49324948",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_materials = list(set(l['lithoklasse_material'] for pt in unique_points for l in pt['layers']))\n",
    "material_to_num = {m: i for i, m in enumerate(all_materials)}\n",
    "num_to_material = {i: m for m, i in material_to_num.items()}\n",
    "\n",
    "smoothed_points = []\n",
    "\n",
    "# Kernel size: sigma in Gaussian filter controls smoothness\n",
    "sigma = 2  # adjust; larger = smoother\n",
    "\n",
    "for pt in unique_points:\n",
    "    layers = sorted(pt['layers'], key=lambda l: l['z'])\n",
    "    z_vals = array([l['z'] for l in layers])\n",
    "    mat_nums = array([material_to_num[l['lithoklasse_material']] for l in layers])\n",
    "    \n",
    "    smoothed_nums = gaussian_filter1d(mat_nums.astype(float), sigma=sigma)\n",
    "    \n",
    "    smoothed_materials = [num_to_material[int(round(n))] for n in smoothed_nums]\n",
    "    \n",
    "    smoothed_layers = [\n",
    "        {'z': z, 'lithoklasse_material': mat, 'lithoklasse_color': material_color_mapping[mat]} \n",
    "        for z, mat in zip(z_vals, smoothed_materials)\n",
    "        ]\n",
    "    \n",
    "    smoothed_points.append({\n",
    "        'lat': pt['lat'],\n",
    "        'lon': pt['lon'],\n",
    "        'layers_smoothed': smoothed_layers\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ft.plot_voxel(\n",
    "    smoothed_points, elev=30, azim=45, \n",
    "    layer_label='layers_smoothed',  dx=0.002, dy=0.002, \n",
    "    save_name='output/smoothed_dataset',\n",
    "    save=False, display_plot=True, figsize=(18,6)\n",
    "    )\n",
    "\n",
    "if save:\n",
    "    print('exporting Gaussian smoothed voxel...')\n",
    "    fig.savefig(f\"output/20251211_Gauss-smoothed_voxel_around_{longitude}-{latitude}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3233cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_smoothed_figs = dict()\n",
    "for azim in linspace(0, 360, 12):\n",
    "    dic_smoothed_figs[azim] = ft.plot_voxel(\n",
    "        smoothed_points, layer_label='layers_smoothed', elev=30, azim=azim, save=True, \n",
    "        save_name='output/smoothed_dataset', display_plot=False, dx=0.002, dy=0.002, figsize=(18,6)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396ea988",
   "metadata": {},
   "source": [
    "### Majority Voting / clustering of adjacent same class layers (chosen)\n",
    "Group in boxes whenever something changed in lat, lon or lithoclasse, <br>\n",
    "creating a box_start and box_end\n",
    "-> z_start - z_end!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c981b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped = points_in_rotterdam.reset_index()\n",
    "\n",
    "print(data_grouped.shape)\n",
    "data_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd5a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped['group'] = (\n",
    "    (data_grouped['lithoklasse'] != data_grouped['lithoklasse'].shift()) |\n",
    "    (data_grouped['lon'] != data_grouped['lon'].shift()) |\n",
    "    (data_grouped['lat'] != data_grouped['lat'].shift())\n",
    ").cumsum()\n",
    "\n",
    "print(data_grouped.shape)\n",
    "data_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf857433",
   "metadata": {},
   "source": [
    "### 3D filling in the vertical space for lithoklasse 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d009ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Literal\n",
    "from numpy import isnan, sort, nan, full, zeros, zeros_like, round, mean, argsort, array_split, where\n",
    "from joblib import Parallel, delayed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_lithoklasse_3d_parallel_safe(\n",
    "    df: DataFrame,\n",
    "    lon_col: str = \"lon\",\n",
    "    lat_col: str = \"lat\",\n",
    "    z_col: str = \"z\",\n",
    "    litho_col: str = \"lithoklasse\",\n",
    "    method: str = \"mean_round\",\n",
    "    round_decimals: int = 6,\n",
    "    n_jobs: int = 4\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Fill lithoklasse==0 cells in a 3D grid using neighbors below and same-level neighbors.\n",
    "    Parallelized safely using NumPy arrays only.\n",
    "    Returns DataFrame with updated lithoklasse and estimated column.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"estimated\"] = False\n",
    "\n",
    "    # Round coordinates to normalize\n",
    "    xs = round(df[lon_col].values.astype(float), round_decimals)\n",
    "    ys = round(df[lat_col].values.astype(float), round_decimals)\n",
    "    zs = round(df[z_col].values.astype(float), round_decimals)\n",
    "\n",
    "    df[\"_gx\"], df[\"_gy\"], df[\"_gz\"] = xs, ys, zs\n",
    "\n",
    "    # Unique sorted coordinates -> integer indices\n",
    "    ux = sort(df[\"_gx\"].unique())\n",
    "    uy = sort(df[\"_gy\"].unique())\n",
    "    uz = sort(df[\"_gz\"].unique())\n",
    "    nx, ny, nz = len(ux), len(uy), len(uz)\n",
    "\n",
    "    x_map = {v: i for i, v in enumerate(ux)}\n",
    "    y_map = {v: i for i, v in enumerate(uy)}\n",
    "    z_map = {v: i for i, v in enumerate(uz)}\n",
    "\n",
    "    arr = full((nx, ny, nz), nan, dtype=float)\n",
    "    idx_map = full((nx, ny, nz), -1, dtype=int)\n",
    "    present = zeros((nx, ny, nz), dtype=bool)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        ix, iy, iz = x_map[row[\"_gx\"]], y_map[row[\"_gy\"]], z_map[row[\"_gz\"]]\n",
    "        arr[ix, iy, iz] = float(row[litho_col])\n",
    "        idx_map[ix, iy, iz] = idx\n",
    "        present[ix, iy, iz] = True\n",
    "\n",
    "    offsets = [(-1,-1),(-1,0),(-1,1),(0,-1),(0,0),(0,1),(1,-1),(1,0),(1,1)]\n",
    "    offsets_same = [o for o in offsets if o != (0,0)]\n",
    "\n",
    "    zero_mask = (arr == 0) & present\n",
    "    z_indices = arange(nz)\n",
    "    \n",
    "    # Process each level sequentially but parallelize cells within the level\n",
    "    for iz in z_indices[1:]:  # skip bottom layer\n",
    "        # Get all zero cells at this level\n",
    "        ix_all, iy_all = where(zero_mask[:, :, iz])\n",
    "        if len(ix_all) == 0:\n",
    "            continue\n",
    "\n",
    "        def process_cell(ix, iy):\n",
    "            neighbors = []\n",
    "\n",
    "            iz_below = iz - 1\n",
    "            for dx, dy in offsets:\n",
    "                x2, y2 = ix+dx, iy+dy\n",
    "                if 0 <= x2 < nx and 0 <= y2 < ny and present[x2, y2, iz_below]:\n",
    "                    v = arr[x2, y2, iz_below]\n",
    "                    if not isnan(v) and int(v) != 0:\n",
    "                        neighbors.append(int(round(v)))\n",
    "\n",
    "            for dx, dy in offsets_same:\n",
    "                x2, y2 = ix+dx, iy+dy\n",
    "                if 0 <= x2 < nx and 0 <= y2 < ny and present[x2, y2, iz]:\n",
    "                    v = arr[x2, y2, iz]\n",
    "                    if not isnan(v) and int(v) != 0:\n",
    "                        neighbors.append(int(round(v)))\n",
    "\n",
    "            if len(neighbors) == 0:\n",
    "                return None\n",
    "\n",
    "            if method == \"mean_round\":\n",
    "                new_val = int(round(mean(neighbors)))\n",
    "            else:\n",
    "                cnt = Counter(neighbors)\n",
    "                max_count = max(cnt.values())\n",
    "                candidates = [val for val, c in cnt.items() if c == max_count]\n",
    "                new_val = int(min(candidates)) \n",
    "\n",
    "            return (ix, iy, new_val)\n",
    "\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(process_cell)(ix_all[i], iy_all[i]) for i in range(len(ix_all))\n",
    "        )\n",
    "\n",
    "        for r in results:\n",
    "            if r is None:\n",
    "                continue\n",
    "            ix, iy, val = r\n",
    "            arr[ix, iy, iz] = val\n",
    "            ridx = idx_map[ix, iy, iz]\n",
    "            df.at[ridx, litho_col] = val\n",
    "            df.at[ridx, \"estimated\"] = True\n",
    "            zero_mask[ix, iy, iz] = False  # mark as filled\n",
    "\n",
    "    df.drop(columns=[\"_gx\", \"_gy\", \"_gz\"], inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled = fill_lithoklasse_3d_parallel_safe(\n",
    "    data_grouped,\n",
    "    method=\"mean_round\",\n",
    "    n_jobs=8 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06414d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8c0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14363cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f088824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a65ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_cols = [col for col in data_grouped.columns if col.startswith('kans_')]\n",
    "likelihood_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237de77b-98fa-4b03-be1f-35970dddb717",
   "metadata": {},
   "source": [
    "When grouping, calculate the average for the columns but for lon, lat, z, lothology and likelihood columns, do the following specifically (agg_dict):\n",
    "- lon / lat → keep single value or list of unique values\n",
    "- z → min and max\n",
    "- lithology → take the first value\n",
    "- likelihood columns → take the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e83a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "    'lon': lambda x: x.iloc[0] if x.nunique() == 1 else list(x.unique()),\n",
    "    'lat': lambda x: x.iloc[0] if x.nunique() == 1 else list(x.unique()),\n",
    "\n",
    "    'z': ['min', 'max'],\n",
    "\n",
    "    'lithostrat': lambda x: x.iloc[0],\n",
    "    'lithoklasse': lambda x: x.iloc[0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf32ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in likelihood_cols:\n",
    "    agg_dict[col] = 'mean'\n",
    "\n",
    "df_grouped = data_grouped.groupby('group').agg(agg_dict)\n",
    "df_grouped.columns = [\n",
    "    f'{c[0]}_{c[1]}' if isinstance(c, tuple) else c\n",
    "    for c in df_grouped.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7cc3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_grouped.rename(columns={\n",
    "    'lon_<lambda>': 'lon',\n",
    "    'lat_<lambda>': 'lat',\n",
    "    'lithoklasse_<lambda>': 'lithoklasse',\n",
    "    'lithostrat_<lambda>': 'lithostrat',\n",
    "})\n",
    "\n",
    "print(df_grouped.shape)\n",
    "df_grouped = df_grouped.reset_index(drop=True)\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df9fb8-e011-455b-8772-fe09bbbdf6db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4a62c-899e-4a71-bb68-5fb646af9062",
   "metadata": {},
   "outputs": [],
   "source": [
    "for grp  in df_grouped[df_grouped.lithoklasse == 0].groupby('lon'):\n",
    "    print(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a22a1-fe02-4477-9420-6899de23cf4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "580422d4-f8d4-4680-9e95-18fffb37445c",
   "metadata": {},
   "source": [
    "Verify averaging to add to 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad28f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kans = data_grouped.filter(like='kans_').sum(axis=1)\n",
    "data_kans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kans.plot(lw=0, marker='o', figsize=(13, 3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d72a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped['lithoklasse_material'] = [map_lithoclasses[k] for k in df_grouped.lithoklasse]\n",
    "df_grouped['lithoklasse_color'] = [material_color_mapping[c] for c in df_grouped['lithoklasse_material']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9298a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = df_grouped[df_grouped['lon'].isin(points_around_input.lon.unique())]\n",
    "filtered = filtered[filtered['lat'].isin(points_around_input.lat.unique())]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824face9",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_grouped, unique_points_grouped = ft.get_unique_points(points_around_input=filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b375ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ft.plot_voxel(\n",
    "    unique_points_grouped, elev=30, azim=45, \n",
    "    layer_label='layers',  dx=0.002, dy=0.002, \n",
    "    save_name='output/smoothed_dataset',\n",
    "    save=False, display_plot=True, figsize=(18,6)\n",
    "    )\n",
    "\n",
    "if save:\n",
    "    fig.savefig(f\"output/20251211_Content-smoothed_voxel_around_{longitude}-{latitude}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# Output as JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b66b3",
   "metadata": {},
   "source": [
    "### Prepare for Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d8315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_kans = df_grouped.filter(like='kans_').columns\n",
    "df_grouped[columns_kans] = df_grouped[columns_kans].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.rename(columns={'z_min': 'z_bottom', 'z_max': 'z_top'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "lithoclass_material = df_grouped['lithoklasse'].map(map_lithoclasses)\n",
    "df_grouped['lithoclass_material'] = lithoclass_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\n",
    "    'lon', 'lat', 'z_top', 'z_bottom', 'lithoklasse', 'lithoclass_material', \n",
    "    'kans_1_veen_mean', 'kans_2_klei_mean', 'kans_3_kleiig_zand_mean', \n",
    "    'kans_4_vervallen_mean', 'kans_5_zand_fijn_mean', 'kans_6_zand_matig_grof_mean', \n",
    "    'kans_7_zand_grof_mean', 'kans_8_grind_mean', 'kans_9_schelpen_mean'\n",
    "]\n",
    "\n",
    "cropped = df_grouped.reset_index()[selected_columns]\n",
    "cropped.rename(columns={\n",
    "    'lithoklasse':'lithoklasse_id', \n",
    "    'lithoclass_material':'lithoklasse'\n",
    "    }, inplace=True)\n",
    "\n",
    "cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiled = cropped.groupby(['lon', 'lat']).apply(\n",
    "    lambda g: sorted(g.to_dict(orient='records'), key=lambda d: d['z_top'], reverse=True)\n",
    ").reset_index(name='data')\n",
    "\n",
    "list_of_lists = profiled['data'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_coordinates_batch = profiled[['lon', 'lat']]\n",
    "map_coordinates_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9267459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_search = 51.924303\n",
    "lon_search = 4.480202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bad56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_coordinates = ft.find_closest_points_to_input(\n",
    "    map_coordinates_batch, lat_search, lon_search, delta_lat=0.001, delta_lon=0.001\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### Export all data in one file\n",
    "\n",
    "for all data points, describe the identified lithoclass (through mapping) and select likelihood of all material being present "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = f\"B01-to-B09_lithoclass_materials_and_likelihood_geocoordinates\"\n",
    "name_file =  f\"_Rotterdam_city_{datetime.now().date().isoformat()}.json\"\n",
    "file_path = dir_export + base_name + name_file\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(list_of_lists, f)\n",
    "\n",
    "print(f\"stored {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Export in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_BYTES = 5 * 1024 * 1024  # 5 MB\n",
    "\n",
    "batch = []\n",
    "batch_size = 0\n",
    "file_index = 1\n",
    "\n",
    "output_dir = dir_export + f\"json_5MB_chunks_{datetime.now().date().isoformat()}/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'Total number of data points: {len(list_of_lists)} '\n",
    "    f'\\nAmount of entries in first set: {len(list_of_lists[0])}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4909dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiled['file_index'] = -1  \n",
    "\n",
    "file_index = 0\n",
    "for idx, sublist in enumerate(list_of_lists):\n",
    "    sublist_bytes = len(json.dumps(sublist, separators=(',', ':')).encode('utf-8'))\n",
    "    if batch_size + sublist_bytes > MAX_BYTES and batch:\n",
    "        file_name = os.path.join(output_dir, f\"litho_batch_{file_index}.json\")\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(batch, f, separators=(',', ':'))\n",
    "        print(f\"Stored {file_name} ({batch_size / 1024**2:.2f} MB)\")\n",
    "        file_index += 1\n",
    "        batch = []\n",
    "        batch_size = 0\n",
    "    \n",
    "    batch.append(sublist)\n",
    "    batch_size += sublist_bytes\n",
    "    profiled.loc[idx, 'batchID'] = file_index  \n",
    "\n",
    "if batch:\n",
    "    file_name = os.path.join(output_dir, f\"litho_batch_{file_index}.json\")\n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(batch, f, separators=(',', ':'))\n",
    "    print(f\"Stored {file_name} ({batch_size / 1024**2:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a25385",
   "metadata": {},
   "source": [
    "## Store map of batch to coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiled[['lon', 'lat', 'batchID']].to_csv(output_dir + 'map_coordinates2batch.txt', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6222192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat([profiled[profiled.lon == lon] for lon in closest_coordinates.lon]).batchID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "# Read JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'output/json_5MB_chunks_2025-12-04/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_files_for_read = [file for file in glob(output_dir + '*.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_df = []\n",
    "for en, path in enumerate(ls_files_for_read):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        print(f\"Reading file {en+1} from {len(ls_files_for_read)}...\")\n",
    "\n",
    "        dfs = []\n",
    "\n",
    "        for f_sub in data:\n",
    "            if isinstance(f_sub, list):\n",
    "                if len(f_sub) > 0 and isinstance(f_sub[0], dict):\n",
    "                    dfs.append(DataFrame(f_sub))\n",
    "                else:\n",
    "                    dfs.append(DataFrame({\"value\": f_sub}))\n",
    "            \n",
    "            elif isinstance(f_sub, dict):\n",
    "                dfs.append(DataFrame([f_sub]))\n",
    "\n",
    "            else:\n",
    "                dfs.append(DataFrame({\"value\": [f_sub]}))\n",
    "\n",
    "        file_df = concat(dfs, ignore_index=True)\n",
    "        ls_df.append(file_df)\n",
    "\n",
    "\n",
    "df_import = concat(ls_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"comparing shapes of datasets:\"\n",
    "    f\"\\n original dataset: {cropped.shape},\"\n",
    "    f\"\\n re-imported dataset: {df_import.shape} and\"\n",
    "    f\"\\n duplicated removed: {df_import.drop_duplicates().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca1aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-env)",
   "language": "python",
   "name": "my-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
